{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "æœ¬æ–‡æ¶‰åŠçš„jupter notebookåœ¨[ç¯‡ç« 4ä»£ç åº“ä¸­](https://github.com/datawhalechina/learn-nlp-with-transformers/tree/main/docs/%E7%AF%87%E7%AB%A04-%E4%BD%BF%E7%94%A8Transformers%E8%A7%A3%E5%86%B3NLP%E4%BB%BB%E5%8A%A1)ã€‚\n",
        "\n",
        "å»ºè®®ç›´æ¥ä½¿ç”¨google colab notebookæ‰“å¼€æœ¬æ•™ç¨‹ï¼Œå¯ä»¥å¿«é€Ÿä¸‹è½½ç›¸å…³æ•°æ®é›†å’Œæ¨¡å‹ã€‚\n",
        "å¦‚æœæ‚¨æ­£åœ¨googleçš„colabä¸­æ‰“å¼€è¿™ä¸ªnotebookï¼Œæ‚¨å¯èƒ½éœ€è¦å®‰è£…Transformerså’ŒğŸ¤—Datasetsåº“ã€‚å°†ä»¥ä¸‹å‘½ä»¤å–æ¶ˆæ³¨é‡Šå³å¯å®‰è£…ã€‚"
      ],
      "metadata": {
        "id": "X4cRE8IbIrIV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "! pip install datasets transformers \"sacrebleu>=1.4.12,<2.0.0\" sentencepiece"
      ],
      "outputs": [],
      "metadata": {
        "id": "MOsHUjgdIrIW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "å¦‚æœæ‚¨æ­£åœ¨æœ¬åœ°æ‰“å¼€è¿™ä¸ªnotebookï¼Œè¯·ç¡®ä¿æ‚¨è®¤çœŸé˜…è¯»å¹¶å®‰è£…äº†transformer-quick-start-zhçš„readmeæ–‡ä»¶ä¸­çš„æ‰€æœ‰ä¾èµ–åº“ã€‚æ‚¨ä¹Ÿå¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/huggingface/transformers/tree/master/examples/seq2seq)æ‰¾åˆ°æœ¬notebookçš„å¤šGPUåˆ†å¸ƒå¼è®­ç»ƒç‰ˆæœ¬ã€‚"
      ],
      "metadata": {
        "id": "HFASsisvIrIb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# å¾®è°ƒtransformeræ¨¡å‹è§£å†³ç¿»è¯‘ä»»åŠ¡"
      ],
      "metadata": {
        "id": "rEJBSTyZIrIb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "åœ¨è¿™ä¸ªnotebookä¸­ï¼Œæˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•ä½¿ç”¨[ğŸ¤— Transformers](https://github.com/huggingface/transformers)ä»£ç åº“ä¸­çš„æ¨¡å‹æ¥è§£å†³è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„ç¿»è¯‘ä»»åŠ¡ã€‚æˆ‘ä»¬å°†ä¼šä½¿ç”¨[WMT dataset](http://www.statmt.org/wmt16/)æ•°æ®é›†ã€‚è¿™æ˜¯ç¿»è¯‘ä»»åŠ¡æœ€å¸¸ç”¨çš„æ•°æ®é›†ä¹‹ä¸€ã€‚\n",
        "\n",
        "ä¸‹é¢å±•ç¤ºäº†ä¸€ä¸ªä¾‹å­ï¼š\n",
        "\n",
        "![Widget inference on a translation task](https://github.com/huggingface/notebooks/blob/master/examples/images/translation.png?raw=1)\n",
        "\n",
        "å¯¹äºç¿»è¯‘ä»»åŠ¡ï¼Œæˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•ä½¿ç”¨ç®€å•çš„åŠ è½½æ•°æ®é›†ï¼ŒåŒæ—¶é’ˆå¯¹ç›¸åº”çš„ä»æ— ä½¿ç”¨transformerä¸­çš„Traineræ¥å£å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚"
      ],
      "metadata": {
        "id": "kTCFado4IrIc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "model_checkpoint = \"Helsinki-NLP/opus-mt-en-ro\" \n",
        "# é€‰æ‹©ä¸€ä¸ªæ¨¡å‹checkpoint"
      ],
      "outputs": [],
      "metadata": {
        "id": "rJvQjiUqPjhM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "åªè¦é¢„è®­ç»ƒçš„transformeræ¨¡å‹åŒ…å«seq2seqç»“æ„çš„headå±‚ï¼Œé‚£ä¹ˆæœ¬notebookç†è®ºä¸Šå¯ä»¥ä½¿ç”¨å„ç§å„æ ·çš„transformeræ¨¡å‹[æ¨¡å‹é¢æ¿](https://huggingface.co/models)ï¼Œè§£å†³ä»»ä½•ç¿»è¯‘ä»»åŠ¡ã€‚\n",
        "\n",
        "æœ¬æ–‡æˆ‘ä»¬ä½¿ç”¨å·²ç»è®­ç»ƒå¥½çš„[`Helsinki-NLP/opus-mt-en-ro`](https://huggingface.co/Helsinki-NLP/opus-mt-en-ro) checkpointæ¥åšç¿»è¯‘ä»»åŠ¡ã€‚ "
      ],
      "metadata": {
        "id": "4RRkXuteIrIh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## åŠ è½½æ•°æ®"
      ],
      "metadata": {
        "id": "whPRbBNbIrIl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "æˆ‘ä»¬å°†ä¼šä½¿ç”¨ğŸ¤— Datasetsåº“æ¥åŠ è½½æ•°æ®å’Œå¯¹åº”çš„è¯„æµ‹æ–¹å¼ã€‚æ•°æ®åŠ è½½å’Œè¯„æµ‹æ–¹å¼åŠ è½½åªéœ€è¦ç®€å•ä½¿ç”¨load_datasetå’Œload_metricå³å¯ã€‚æˆ‘ä»¬ä½¿ç”¨WMTæ•°æ®é›†ä¸­çš„English/RomanianåŒè¯­ç¿»è¯‘ã€‚\n"
      ],
      "metadata": {
        "id": "W7QYTpxXIrIl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "from datasets import load_dataset, load_metric\n",
        "\n",
        "raw_datasets = load_dataset(\"wmt16\", \"ro-en\")\n",
        "metric = load_metric(\"sacrebleu\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: 2.81kB [00:00, 523kB/s]                    \n",
            "Downloading: 3.19kB [00:00, 758kB/s]                    \n",
            "Downloading: 41.0kB [00:00, 11.0MB/s]                   \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset wmt16/ro-en (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /Users/niepig/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/0d9fb3e814712c785176ad8cdb9f465fbe6479000ee6546725db30ad8a8b5f8a...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225M/225M [00:18<00:00, 12.2MB/s]\n",
            "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23.5M/23.5M [00:16<00:00, 1.44MB/s]\n",
            "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38.7M/38.7M [00:03<00:00, 9.82MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset wmt16 downloaded and prepared to /Users/niepig/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/0d9fb3e814712c785176ad8cdb9f465fbe6479000ee6546725db30ad8a8b5f8a. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: 5.40kB [00:00, 2.08MB/s]                   \n"
          ]
        }
      ],
      "metadata": {
        "id": "IreSlFmlIrIm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "è¿™ä¸ªdatasetså¯¹è±¡æœ¬èº«æ˜¯ä¸€ç§[`DatasetDict`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasetdict)æ•°æ®ç»“æ„. å¯¹äºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ï¼Œåªéœ€è¦ä½¿ç”¨å¯¹åº”çš„keyï¼ˆtrainï¼Œvalidationï¼Œtestï¼‰å³å¯å¾—åˆ°ç›¸åº”çš„æ•°æ®ã€‚"
      ],
      "metadata": {
        "id": "RzfPtOMoIrIu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "raw_datasets"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['translation'],\n",
              "        num_rows: 610320\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['translation'],\n",
              "        num_rows: 1999\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['translation'],\n",
              "        num_rows: 1999\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWiVUF0jIrIv",
        "outputId": "3151a9fc-7239-4471-a8f0-548dd68d5a89"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ç»™å®šä¸€ä¸ªæ•°æ®åˆ‡åˆ†çš„keyï¼ˆtrainã€validationæˆ–è€…testï¼‰å’Œä¸‹æ ‡å³å¯æŸ¥çœ‹æ•°æ®ã€‚"
      ],
      "metadata": {
        "id": "u3EtYfeHIrIz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "raw_datasets[\"train\"][0]\n",
        "# æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä¸€å¥è‹±è¯­enå¯¹åº”ä¸€å¥ç½—é©¬å°¼äºšè¯­è¨€ro"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'translation': {'en': 'Membership of Parliament: see Minutes',\n",
              "  'ro': 'ComponenÅ£a Parlamentului: a se vedea procesul-verbal'}}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6HrpprwIrIz",
        "outputId": "69f3873e-2d1f-4614-e43e-9e654277245c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ä¸ºäº†èƒ½å¤Ÿè¿›ä¸€æ­¥ç†è§£æ•°æ®é•¿ä»€ä¹ˆæ ·å­ï¼Œä¸‹é¢çš„å‡½æ•°å°†ä»æ•°æ®é›†é‡Œéšæœºé€‰æ‹©å‡ ä¸ªä¾‹å­è¿›è¡Œå±•ç¤ºã€‚"
      ],
      "metadata": {
        "id": "WHUmphG3IrI3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "import datasets\n",
        "import random\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "def show_random_elements(dataset, num_examples=5):\n",
        "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
        "    picks = []\n",
        "    for _ in range(num_examples):\n",
        "        pick = random.randint(0, len(dataset)-1)\n",
        "        while pick in picks:\n",
        "            pick = random.randint(0, len(dataset)-1)\n",
        "        picks.append(pick)\n",
        "    \n",
        "    df = pd.DataFrame(dataset[picks])\n",
        "    for column, typ in dataset.features.items():\n",
        "        if isinstance(typ, datasets.ClassLabel):\n",
        "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
        "    display(HTML(df.to_html()))"
      ],
      "outputs": [],
      "metadata": {
        "id": "i3j8APAoIrI3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "show_random_elements(raw_datasets[\"train\"])"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>translation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'en': 'I do not believe that this is the right course.', 'ro': 'Nu cred cÄƒ acesta este varianta corectÄƒ.'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'en': 'A total of 104 new jobs were created at the European Chemicals Agency, which mainly supervises our REACH projects.', 'ro': 'Un total de 104 noi locuri de muncÄƒ au fost create la AgenÈ›ia EuropeanÄƒ pentru Produse Chimice, care, Ã®n special, supravegheazÄƒ proiectele noastre REACH.'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'en': 'In view of the above, will the Council say what stage discussions for Turkish participation in joint Frontex operations have reached?', 'ro': 'Care este stadiul negocierilor referitoare la participarea Turciei la operaÈ›iunile comune din cadrul Frontex?'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'en': 'We now fear that if the scope of this directive is expanded, the directive will suffer exactly the same fate as the last attempt at introducing 'Made in' origin marking - in other words, that it will once again be blocked by the Council.', 'ro': 'Acum ne temem cÄƒ, dacÄƒ sfera de aplicare a directivei va fi extinsÄƒ, aceasta va avea exact aceeaÅŸi soartÄƒ ca ultima Ã®ncercare de introducere a marcajului de origine \"Made inâ€, cu alte cuvinte, cÄƒ va fi din nou blocatÄƒ la Consiliu.'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'en': 'The country dropped nine slots to 85th, with a score of 6.58.', 'ro': 'Å¢ara a coborÃ¢t nouÄƒ poziÅ£ii, pe locul 85, cu un scor de 6,58.'}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "SZy5tRB_IrI7",
        "outputId": "93e16172-d927-457d-fcab-04dcb4d2ef29"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "metricæ˜¯[`datasets.Metric`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Metric)ç±»çš„ä¸€ä¸ªå®ä¾‹ï¼ŒæŸ¥çœ‹metricå’Œä½¿ç”¨çš„ä¾‹å­:"
      ],
      "metadata": {
        "id": "lnjDIuQ3IrI-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "metric"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Metric(name: \"sacrebleu\", features: {'predictions': Value(dtype='string', id='sequence'), 'references': Sequence(feature=Value(dtype='string', id='sequence'), length=-1, id='references')}, usage: \"\"\"\n",
              "Produces BLEU scores along with its sufficient statistics\n",
              "from a source against one or more references.\n",
              "\n",
              "Args:\n",
              "    predictions: The system stream (a sequence of segments)\n",
              "    references: A list of one or more reference streams (each a sequence of segments)\n",
              "    smooth: The smoothing method to use\n",
              "    smooth_value: For 'floor' smoothing, the floor to use\n",
              "    force: Ignore data that looks already tokenized\n",
              "    lowercase: Lowercase the data\n",
              "    tokenize: The tokenizer to use\n",
              "Returns:\n",
              "    'score': BLEU score,\n",
              "    'counts': Counts,\n",
              "    'totals': Totals,\n",
              "    'precisions': Precisions,\n",
              "    'bp': Brevity penalty,\n",
              "    'sys_len': predictions length,\n",
              "    'ref_len': reference length,\n",
              "Examples:\n",
              "\n",
              "    >>> predictions = [\"hello there general kenobi\", \"foo bar foobar\"]\n",
              "    >>> references = [[\"hello there general kenobi\", \"hello there !\"], [\"foo bar foobar\", \"foo bar foobar\"]]\n",
              "    >>> sacrebleu = datasets.load_metric(\"sacrebleu\")\n",
              "    >>> results = sacrebleu.compute(predictions=predictions, references=references)\n",
              "    >>> print(list(results.keys()))\n",
              "    ['score', 'counts', 'totals', 'precisions', 'bp', 'sys_len', 'ref_len']\n",
              "    >>> print(round(results[\"score\"], 1))\n",
              "    100.0\n",
              "\"\"\", stored examples: 0)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5o4rUteaIrI_",
        "outputId": "4814f907-6225-4af0-ee63-376699dc79ee"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "æˆ‘ä»¬ä½¿ç”¨`compute`æ–¹æ³•æ¥å¯¹æ¯”predictionså’Œlabelsï¼Œä»è€Œè®¡ç®—å¾—åˆ†ã€‚predictionså’Œlabelséƒ½éœ€è¦æ˜¯ä¸€ä¸ªlistã€‚å…·ä½“æ ¼å¼è§ä¸‹é¢çš„ä¾‹å­ï¼š"
      ],
      "metadata": {
        "id": "jAWdqcUBIrJC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "fake_preds = [\"hello there\", \"general kenobi\"]\n",
        "fake_labels = [[\"hello there\"], [\"general kenobi\"]]\n",
        "metric.compute(predictions=fake_preds, references=fake_labels)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.0,\n",
              " 'counts': [4, 2, 0, 0],\n",
              " 'totals': [4, 2, 0, 0],\n",
              " 'precisions': [100.0, 100.0, 0.0, 0.0],\n",
              " 'bp': 1.0,\n",
              " 'sys_len': 4,\n",
              " 'ref_len': 4}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XN1Rq0aIrJC",
        "outputId": "d130ad50-c6ca-42bc-8b14-31021feb620d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## æ•°æ®é¢„å¤„ç†"
      ],
      "metadata": {
        "id": "n9qywopnIrJH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "åœ¨å°†æ•°æ®å–‚å…¥æ¨¡å‹ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†ã€‚é¢„å¤„ç†çš„å·¥å…·å«Tokenizerã€‚Tokenizeré¦–å…ˆå¯¹è¾“å…¥è¿›è¡Œtokenizeï¼Œç„¶åå°†tokensè½¬åŒ–ä¸ºé¢„æ¨¡å‹ä¸­éœ€è¦å¯¹åº”çš„token IDï¼Œå†è½¬åŒ–ä¸ºæ¨¡å‹éœ€è¦çš„è¾“å…¥æ ¼å¼ã€‚\n",
        "\n",
        "ä¸ºäº†è¾¾åˆ°æ•°æ®é¢„å¤„ç†çš„ç›®çš„ï¼Œæˆ‘ä»¬ä½¿ç”¨AutoTokenizer.from_pretrainedæ–¹æ³•å®ä¾‹åŒ–æˆ‘ä»¬çš„tokenizerï¼Œè¿™æ ·å¯ä»¥ç¡®ä¿ï¼š\n",
        "\n",
        "- æˆ‘ä»¬å¾—åˆ°ä¸€ä¸ªä¸é¢„è®­ç»ƒæ¨¡å‹ä¸€ä¸€å¯¹åº”çš„tokenizerã€‚\n",
        "- ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹checkpointå¯¹åº”çš„tokenizerçš„æ—¶å€™ï¼Œæˆ‘ä»¬ä¹Ÿä¸‹è½½äº†æ¨¡å‹éœ€è¦çš„è¯è¡¨åº“vocabularyï¼Œå‡†ç¡®æ¥è¯´æ˜¯tokens vocabularyã€‚\n",
        "\n",
        "\n",
        "è¿™ä¸ªè¢«ä¸‹è½½çš„tokens vocabularyä¼šè¢«ç¼“å­˜èµ·æ¥ï¼Œä»è€Œå†æ¬¡ä½¿ç”¨çš„æ—¶å€™ä¸ä¼šé‡æ–°ä¸‹è½½ã€‚"
      ],
      "metadata": {
        "id": "YVx71GdAIrJH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "from transformers import AutoTokenizer\n",
        "# éœ€è¦å®‰è£…`sentencepiece`ï¼š pip install sentencepiece\n",
        "    \n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.13k/1.13k [00:00<00:00, 466kB/s]\n",
            "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 789k/789k [00:00<00:00, 882kB/s]\n",
            "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 817k/817k [00:00<00:00, 902kB/s]\n",
            "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.39M/1.39M [00:01<00:00, 1.24MB/s]\n",
            "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42.0/42.0 [00:00<00:00, 14.6kB/s]\n"
          ]
        }
      ],
      "metadata": {
        "id": "eXNLu_-nIrJI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ä»¥æˆ‘ä»¬ä½¿ç”¨çš„mBARTæ¨¡å‹ä¸ºä¾‹ï¼Œæˆ‘ä»¬éœ€è¦æ­£ç¡®è®¾ç½®sourceè¯­è¨€å’Œtargetè¯­è¨€ã€‚å¦‚æœæ‚¨è¦ç¿»è¯‘çš„æ˜¯å…¶ä»–åŒè¯­è¯­æ–™ï¼Œè¯·æŸ¥çœ‹[è¿™é‡Œ](https://huggingface.co/facebook/mbart-large-cc25)ã€‚æˆ‘ä»¬å¯ä»¥æ£€æŸ¥sourceå’Œtargetè¯­è¨€çš„è®¾ç½®ï¼š\n"
      ],
      "metadata": {
        "id": "GLRyc5J9PjhS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "if \"mbart\" in model_checkpoint:\n",
        "    tokenizer.src_lang = \"en-XX\"\n",
        "    tokenizer.tgt_lang = \"ro-RO\""
      ],
      "outputs": [],
      "metadata": {
        "id": "kmXG36baPjhS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Vl6IidfdIrJK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "tokenizeræ—¢å¯ä»¥å¯¹å•ä¸ªæ–‡æœ¬è¿›è¡Œé¢„å¤„ç†ï¼Œä¹Ÿå¯ä»¥å¯¹ä¸€å¯¹æ–‡æœ¬è¿›è¡Œé¢„å¤„ç†ï¼Œtokenizeré¢„å¤„ç†åå¾—åˆ°çš„æ•°æ®æ»¡è¶³é¢„è®­ç»ƒæ¨¡å‹è¾“å…¥æ ¼å¼"
      ],
      "metadata": {
        "id": "rowT4iCLIrJK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "tokenizer(\"Hello, this one sentence!\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [125, 778, 3, 63, 141, 9191, 23, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5hBlsrHIrJL",
        "outputId": "072ee20c-db1d-4ba1-a98a-119405ea9552"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ä¸Šé¢çœ‹åˆ°çš„token IDsä¹Ÿå°±æ˜¯input_idsä¸€èˆ¬æ¥è¯´éšç€é¢„è®­ç»ƒæ¨¡å‹åå­—çš„ä¸åŒè€Œæœ‰æ‰€ä¸åŒã€‚åŸå› æ˜¯ä¸åŒçš„é¢„è®­ç»ƒæ¨¡å‹åœ¨é¢„è®­ç»ƒçš„æ—¶å€™è®¾å®šäº†ä¸åŒçš„è§„åˆ™ã€‚ä½†åªè¦tokenizerå’Œmodelçš„åå­—ä¸€è‡´ï¼Œé‚£ä¹ˆtokenizeré¢„å¤„ç†çš„è¾“å…¥æ ¼å¼å°±ä¼šæ»¡è¶³modeléœ€æ±‚çš„ã€‚å…³äºé¢„å¤„ç†æ›´å¤šå†…å®¹å‚è€ƒ[è¿™ä¸ªæ•™ç¨‹](https://huggingface.co/transformers/preprocessing.html)\n",
        "\n",
        "é™¤äº†å¯ä»¥tokenizeä¸€å¥è¯ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥tokenizeä¸€ä¸ªlistçš„å¥å­ã€‚"
      ],
      "metadata": {
        "id": "qo_0B1M2IrJM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "tokenizer([\"Hello, this one sentence!\", \"This is another sentence.\"])"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[125, 778, 3, 63, 141, 9191, 23, 0], [187, 32, 716, 9191, 2, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]]}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkLffVlKPjhT",
        "outputId": "f144d050-fc84-4a1a-9fc2-25281b681441"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "æ³¨æ„ï¼šä¸ºäº†ç»™æ¨¡å‹å‡†å¤‡å¥½ç¿»è¯‘çš„targetsï¼Œæˆ‘ä»¬ä½¿ç”¨`as_target_tokenizer`æ¥æ§åˆ¶targetsæ‰€å¯¹åº”çš„ç‰¹æ®Štokenï¼š"
      ],
      "metadata": {
        "id": "-uVqYJrePjhT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "with tokenizer.as_target_tokenizer():\n",
        "    print(tokenizer(\"Hello, this one sentence!\"))\n",
        "    model_input = tokenizer(\"Hello, this one sentence!\")\n",
        "    tokens = tokenizer.convert_ids_to_tokens(model_input['input_ids'])\n",
        "    # æ‰“å°çœ‹ä¸€ä¸‹special toke\n",
        "    print('tokens: {}'.format(tokens))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [10334, 1204, 3, 15, 8915, 27, 452, 59, 29579, 581, 23, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "tokens: ['â–Hel', 'lo', ',', 'â–', 'this', 'â–o', 'ne', 'â–se', 'nten', 'ce', '!', '</s>']\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgCW0X0FPjhT",
        "outputId": "352c44ab-f025-4cf6-98d1-786f6f07111a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "å¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯T5é¢„è®­ç»ƒæ¨¡å‹çš„checkpointsï¼Œéœ€è¦å¯¹ç‰¹æ®Šçš„å‰ç¼€è¿›è¡Œæ£€æŸ¥ã€‚T5ä½¿ç”¨ç‰¹æ®Šçš„å‰ç¼€æ¥å‘Šè¯‰æ¨¡å‹å…·ä½“è¦åšçš„ä»»åŠ¡ï¼Œå…·ä½“å‰ç¼€ä¾‹å­å¦‚ä¸‹ï¼š\n"
      ],
      "metadata": {
        "id": "2C0hcmp9IrJQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "source": [
        "if model_checkpoint in [\"t5-small\", \"t5-base\", \"t5-larg\", \"t5-3b\", \"t5-11b\"]:\n",
        "    prefix = \"translate English to Romanian: \"\n",
        "else:\n",
        "    prefix = \"\""
      ],
      "outputs": [],
      "metadata": {
        "id": "xS1JJSdmPjhU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ç°åœ¨æˆ‘ä»¬å¯ä»¥æŠŠæ‰€æœ‰å†…å®¹æ”¾åœ¨ä¸€èµ·ç»„æˆæˆ‘ä»¬çš„é¢„å¤„ç†å‡½æ•°äº†ã€‚æˆ‘ä»¬å¯¹æ ·æœ¬è¿›è¡Œé¢„å¤„ç†çš„æ—¶å€™ï¼Œæˆ‘ä»¬è¿˜ä¼š`truncation=True`è¿™ä¸ªå‚æ•°æ¥ç¡®ä¿æˆ‘ä»¬è¶…é•¿çš„å¥å­è¢«æˆªæ–­ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œå¯¹ä¸æ¯”è¾ƒçŸ­çš„å¥å­æˆ‘ä»¬ä¼šè‡ªåŠ¨paddingã€‚"
      ],
      "metadata": {
        "id": "CezpZ8gFPjhU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "source": [
        "max_input_length = 128\n",
        "max_target_length = 128\n",
        "source_lang = \"en\"\n",
        "target_lang = \"ro\"\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = [prefix + ex[source_lang] for ex in examples[\"translation\"]]\n",
        "    targets = [ex[target_lang] for ex in examples[\"translation\"]]\n",
        "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
        "\n",
        "    # Setup the tokenizer for targets\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ],
      "outputs": [],
      "metadata": {
        "id": "vc0BSBLIIrJQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ä»¥ä¸Šçš„é¢„å¤„ç†å‡½æ•°å¯ä»¥å¤„ç†ä¸€ä¸ªæ ·æœ¬ï¼Œä¹Ÿå¯ä»¥å¤„ç†å¤šä¸ªæ ·æœ¬exapmlesã€‚å¦‚æœæ˜¯å¤„ç†å¤šä¸ªæ ·æœ¬ï¼Œåˆ™è¿”å›çš„æ˜¯å¤šä¸ªæ ·æœ¬è¢«é¢„å¤„ç†ä¹‹åçš„ç»“æœlistã€‚"
      ],
      "metadata": {
        "id": "0lm8ozrJIrJR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "preprocess_function(raw_datasets['train'][:2])"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[393, 4462, 14, 1137, 53, 216, 28636, 0], [24385, 14, 28636, 14, 4646, 4622, 53, 216, 28636, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[42140, 494, 1750, 53, 8, 59, 903, 3543, 9, 15202, 0], [36199, 6612, 9, 15202, 122, 568, 35788, 21549, 53, 8, 59, 903, 3543, 9, 15202, 0]]}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-b70jh26IrJS",
        "outputId": "89b26088-d2d2-4312-81d8-b0f5e62dd6a2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "æ¥ä¸‹æ¥å¯¹æ•°æ®é›†datasetsé‡Œé¢çš„æ‰€æœ‰æ ·æœ¬è¿›è¡Œé¢„å¤„ç†ï¼Œå¤„ç†çš„æ–¹å¼æ˜¯ä½¿ç”¨mapå‡½æ•°ï¼Œå°†é¢„å¤„ç†å‡½æ•°prepare_train_featuresåº”ç”¨åˆ°ï¼ˆmap)æ‰€æœ‰æ ·æœ¬ä¸Šã€‚"
      ],
      "metadata": {
        "id": "zS-6iXTkIrJT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "source": [
        "tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 611/611 [02:32<00:00,  3.99ba/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.76ba/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.89ba/s]\n"
          ]
        }
      ],
      "metadata": {
        "id": "DDtsaJeVIrJT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "æ›´å¥½çš„æ˜¯ï¼Œè¿”å›çš„ç»“æœä¼šè‡ªåŠ¨è¢«ç¼“å­˜ï¼Œé¿å…ä¸‹æ¬¡å¤„ç†çš„æ—¶å€™é‡æ–°è®¡ç®—ï¼ˆä½†æ˜¯ä¹Ÿè¦æ³¨æ„ï¼Œå¦‚æœè¾“å…¥æœ‰æ”¹åŠ¨ï¼Œå¯èƒ½ä¼šè¢«ç¼“å­˜å½±å“ï¼ï¼‰ã€‚datasetsåº“å‡½æ•°ä¼šå¯¹è¾“å…¥çš„å‚æ•°è¿›è¡Œæ£€æµ‹ï¼Œåˆ¤æ–­æ˜¯å¦æœ‰å˜åŒ–ï¼Œå¦‚æœæ²¡æœ‰å˜åŒ–å°±ä½¿ç”¨ç¼“å­˜æ•°æ®ï¼Œå¦‚æœæœ‰å˜åŒ–å°±é‡æ–°å¤„ç†ã€‚ä½†å¦‚æœè¾“å…¥å‚æ•°ä¸å˜ï¼Œæƒ³æ”¹å˜è¾“å…¥çš„æ—¶å€™ï¼Œæœ€å¥½æ¸…ç†è°ƒè¿™ä¸ªç¼“å­˜ã€‚æ¸…ç†çš„æ–¹å¼æ˜¯ä½¿ç”¨`load_from_cache_file=False`å‚æ•°ã€‚å¦å¤–ï¼Œä¸Šé¢ä½¿ç”¨åˆ°çš„`batched=True`è¿™ä¸ªå‚æ•°æ˜¯tokenizerçš„ç‰¹ç‚¹ï¼Œä»¥ä¸ºè¿™ä¼šä½¿ç”¨å¤šçº¿ç¨‹åŒæ—¶å¹¶è¡Œå¯¹è¾“å…¥è¿›è¡Œå¤„ç†ã€‚"
      ],
      "metadata": {
        "id": "voWiw8C7IrJV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## å¾®è°ƒtransformeræ¨¡å‹"
      ],
      "metadata": {
        "id": "545PP3o8IrJV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "æ—¢ç„¶æ•°æ®å·²ç»å‡†å¤‡å¥½äº†ï¼Œç°åœ¨æˆ‘ä»¬éœ€è¦ä¸‹è½½å¹¶åŠ è½½æˆ‘ä»¬çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œç„¶åå¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹ã€‚æ—¢ç„¶æˆ‘ä»¬æ˜¯åšseq2seqä»»åŠ¡ï¼Œé‚£ä¹ˆæˆ‘ä»¬éœ€è¦ä¸€ä¸ªèƒ½è§£å†³è¿™ä¸ªä»»åŠ¡çš„æ¨¡å‹ç±»ã€‚æˆ‘ä»¬ä½¿ç”¨`AutoModelForSeq2SeqLM`è¿™ä¸ªç±»ã€‚å’Œtokenizerç›¸ä¼¼ï¼Œ`from_pretrained`æ–¹æ³•åŒæ ·å¯ä»¥å¸®åŠ©æˆ‘ä»¬ä¸‹è½½å¹¶åŠ è½½æ¨¡å‹ï¼ŒåŒæ—¶ä¹Ÿä¼šå¯¹æ¨¡å‹è¿›è¡Œç¼“å­˜ï¼Œå°±ä¸ä¼šé‡å¤ä¸‹è½½æ¨¡å‹å•¦ã€‚"
      ],
      "metadata": {
        "id": "FBiW8UpKIrJW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 301M/301M [00:19<00:00, 15.1MB/s]\n"
          ]
        }
      ],
      "metadata": {
        "id": "TlqNaB8jIrJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ç”±äºæˆ‘ä»¬å¾®è°ƒçš„ä»»åŠ¡æ˜¯æœºå™¨ç¿»è¯‘ï¼Œè€Œæˆ‘ä»¬åŠ è½½çš„æ˜¯é¢„è®­ç»ƒçš„seq2seqæ¨¡å‹ï¼Œæ‰€ä»¥ä¸ä¼šæç¤ºæˆ‘ä»¬åŠ è½½æ¨¡å‹çš„æ—¶å€™æ‰”æ‰äº†ä¸€äº›ä¸åŒ¹é…çš„ç¥ç»ç½‘ç»œå‚æ•°ï¼ˆæ¯”å¦‚ï¼šé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„ç¥ç»ç½‘ç»œheadè¢«æ‰”æ‰äº†ï¼ŒåŒæ—¶éšæœºåˆå§‹åŒ–äº†æœºå™¨ç¿»è¯‘çš„ç¥ç»ç½‘ç»œheadï¼‰ã€‚"
      ],
      "metadata": {
        "id": "CczA5lJlIrJX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "ä¸ºäº†èƒ½å¤Ÿå¾—åˆ°ä¸€ä¸ª`Seq2SeqTrainer`è®­ç»ƒå·¥å…·ï¼Œæˆ‘ä»¬è¿˜éœ€è¦3ä¸ªè¦ç´ ï¼Œå…¶ä¸­æœ€é‡è¦çš„æ˜¯è®­ç»ƒçš„è®¾å®š/å‚æ•°[`Seq2SeqTrainingArguments`](https://huggingface.co/transformers/main_classes/trainer.html#transformers.Seq2SeqTrainingArguments)ã€‚è¿™ä¸ªè®­ç»ƒè®¾å®šåŒ…å«äº†èƒ½å¤Ÿå®šä¹‰è®­ç»ƒè¿‡ç¨‹çš„æ‰€æœ‰å±æ€§"
      ],
      "metadata": {
        "id": "_N8urzhyIrJY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "source": [
        "batch_size = 16\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    \"test-translation\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=1,\n",
        "    predict_with_generate=True,\n",
        "    fp16=False,\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "Bliy8zgjIrJY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ä¸Šé¢evaluation_strategy = \"epoch\"å‚æ•°å‘Šè¯‰è®­ç»ƒä»£ç ï¼šæˆ‘ä»¬æ¯ä¸ªepcohä¼šåšä¸€æ¬¡éªŒè¯è¯„ä¼°ã€‚\n",
        "\n",
        "ä¸Šé¢batch_sizeåœ¨è¿™ä¸ªnotebookä¹‹å‰å®šä¹‰å¥½äº†ã€‚\n",
        "\n",
        "ç”±äºæˆ‘ä»¬çš„æ•°æ®é›†æ¯”è¾ƒå¤§ï¼ŒåŒæ—¶`Seq2SeqTrainer`ä¼šä¸æ–­ä¿å­˜æ¨¡å‹ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦å‘Šè¯‰å®ƒè‡³å¤šä¿å­˜`save_total_limit=3`ä¸ªæ¨¡å‹ã€‚\n",
        "\n",
        "æœ€åæˆ‘ä»¬éœ€è¦ä¸€ä¸ªæ•°æ®æ”¶é›†å™¨data collatorï¼Œå°†æˆ‘ä»¬å¤„ç†å¥½çš„è¾“å…¥å–‚ç»™æ¨¡å‹ã€‚"
      ],
      "metadata": {
        "id": "km3pGVdTIrJc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ],
      "outputs": [],
      "metadata": {
        "id": "ZMdgZaOoPjhX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "è®¾ç½®å¥½`Seq2SeqTrainer`è¿˜å‰©æœ€åä¸€ä»¶äº‹æƒ…ï¼Œé‚£å°±æ˜¯æˆ‘ä»¬éœ€è¦å®šä¹‰å¥½è¯„ä¼°æ–¹æ³•ã€‚æˆ‘ä»¬ä½¿ç”¨`metric`æ¥å®Œæˆè¯„ä¼°ã€‚å°†æ¨¡å‹é¢„æµ‹é€å…¥è¯„ä¼°ä¹‹å‰ï¼Œæˆ‘ä»¬ä¹Ÿä¼šåšä¸€äº›æ•°æ®åå¤„ç†ï¼š"
      ],
      "metadata": {
        "id": "7sZOdRlRIrJd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "source": [
        "import numpy as np\n",
        "\n",
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [[label.strip()] for label in labels]\n",
        "\n",
        "    return preds, labels\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Some simple post-processing\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    result = {\"bleu\": result[\"score\"]}\n",
        "\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    result = {k: round(v, 4) for k, v in result.items()}\n",
        "    return result"
      ],
      "outputs": [],
      "metadata": {
        "id": "UmvbnJ9JIrJd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "æœ€åå°†æ‰€æœ‰çš„å‚æ•°/æ•°æ®/æ¨¡å‹ä¼ ç»™`Seq2SeqTrainer`å³å¯"
      ],
      "metadata": {
        "id": "rXuFTAzDIrJe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "imY1oC3SIrJf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "è°ƒç”¨`train`æ–¹æ³•è¿›è¡Œå¾®è°ƒè®­ç»ƒã€‚"
      ],
      "metadata": {
        "id": "CdzABDVcIrJg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "trainer.train()"
      ],
      "outputs": [],
      "metadata": {
        "id": "uNx5pyRlIrJh",
        "scrolled": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "æœ€ååˆ«å¿˜äº†ï¼ŒæŸ¥çœ‹å¦‚ä½•ä¸Šä¼ æ¨¡å‹ ï¼Œä¸Šä¼ æ¨¡å‹åˆ°](https://huggingface.co/transformers/model_sharing.html) åˆ°[ğŸ¤— Model Hub](https://huggingface.co/models)ã€‚éšåæ‚¨å°±å¯ä»¥åƒè¿™ä¸ªnotebookä¸€å¼€å§‹ä¸€æ ·ï¼Œç›´æ¥ç”¨æ¨¡å‹åå­—å°±èƒ½ä½¿ç”¨æ‚¨çš„æ¨¡å‹å•¦ã€‚\n"
      ],
      "metadata": {
        "id": "JXOyGJtqPjhZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "Jeq1Cq2yPjhZ"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "4.6-ç”Ÿæˆä»»åŠ¡-æœºå™¨ç¿»è¯‘",
      "provenance": []
    },
    "interpreter": {
      "hash": "3bfce0b4c492a35815b5705a19fe374a7eea0baaa08b34d90450caf1fe9ce20b"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.10 64-bit ('venv': virtualenv)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}