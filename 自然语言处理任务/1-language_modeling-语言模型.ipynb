{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¦‚æœæ‚¨åœ¨colabä¸Šæ‰“å¼€è¿™ä¸ªjupyterç¬”è®°æœ¬ï¼Œæ‚¨éœ€è¦å®‰è£…ğŸ¤—Trasnformerså’ŒğŸ¤—datasetsã€‚å…·ä½“å‘½ä»¤å¦‚ä¸‹ï¼ˆå–æ¶ˆæ³¨é‡Šå¹¶è¿è¡Œï¼Œå¦‚æœé€Ÿåº¦æ…¢è¯·åˆ‡æ¢å›½å†…æºï¼ŒåŠ ä¸Šç¬¬äºŒè¡Œçš„å‚æ•°ï¼‰ã€‚\n",
    "\n",
    "åœ¨è¿è¡Œå•å…ƒæ ¼ä¹‹å‰ï¼Œæ‚¨éœ€è¦ç¡®ä¿æ‚¨ä½¿ç”¨çš„pythonç¯å¢ƒå’Œè¯¥é¡¹ç›®ä¸­çš„README.mdæ–‡ä»¶ä¸­æè¿°çš„ä¸€è‡´ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install datasets transformers \n",
    "# -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¦‚æœæ‚¨æ˜¯åœ¨æœ¬åœ°æœºå™¨ä¸Šæ‰“å¼€è¿™ä¸ªjupyterç¬”è®°æœ¬ï¼Œè¯·ç¡®ä¿æ‚¨çš„ç¯å¢ƒå®‰è£…äº†ä¸Šè¿°åº“çš„æœ€æ–°ç‰ˆæœ¬ã€‚\n",
    "\n",
    "æ‚¨å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/huggingface/transformers/tree/master/examples/language-modeling)æ‰¾åˆ°è¿™ä¸ªjupyterç¬”è®°æœ¬çš„å…·ä½“çš„pythonè„šæœ¬æ–‡ä»¶ï¼Œè¿˜å¯ä»¥é€šè¿‡åˆ†å¸ƒå¼çš„æ–¹å¼ä½¿ç”¨å¤šä¸ªgpuæˆ–tpuæ¥å¾®è°ƒæ‚¨çš„æ¨¡å‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# å¾®è°ƒæ‚¨çš„è¯­è¨€æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨å½“å‰jupyterç¬”è®°æœ¬ä¸­ï¼Œæˆ‘ä»¬å°†è¯´æ˜å¦‚ä½•ä½¿ç”¨è¯­è¨€æ¨¡å‹ä»»åŠ¡å¾®è°ƒä»»æ„[ğŸ¤—Transformers](https://github.com/huggingface/transformers) æ¨¡å‹ã€‚ \n",
    "\n",
    "æœ¬æ•™ç¨‹å°†æ¶µç›–ä¸¤ç§ç±»å‹çš„è¯­è¨€å»ºæ¨¡ä»»åŠ¡:\n",
    "\n",
    "+ å› æœè¯­è¨€æ¨¡å‹ï¼ˆCausal language modelingï¼ŒCLMï¼‰ï¼šæ¨¡å‹éœ€è¦é¢„æµ‹å¥å­ä¸­çš„ä¸‹ä¸€ä½ç½®å¤„çš„å­—ç¬¦ï¼ˆç±»ä¼¼BERTç±»æ¨¡å‹çš„decoderå’ŒGPTï¼Œä»å·¦å¾€å³è¾“å…¥å­—ç¬¦ï¼‰ã€‚ä¸ºäº†ç¡®ä¿æ¨¡å‹ä¸ä½œå¼Šï¼Œæ¨¡å‹ä¼šä½¿ç”¨ä¸€ä¸ªæ³¨æ„æ©ç é˜²æ­¢æ¨¡å‹çœ‹åˆ°ä¹‹åçš„å­—ç¬¦ã€‚ä¾‹å¦‚ï¼Œå½“æ¨¡å‹è¯•å›¾é¢„æµ‹å¥å­ä¸­çš„i+1ä½ç½®å¤„çš„å­—ç¬¦æ—¶ï¼Œè¿™ä¸ªæ©ç å°†é˜»æ­¢å®ƒè®¿é—®iä½ç½®ä¹‹åçš„å­—ç¬¦ã€‚\n",
    "\n",
    "![æ¨ç†è¡¨ç¤ºå› æœè¯­è¨€å»ºæ¨¡ä»»åŠ¡å›¾ç‰‡](images/causal_language_modeling.png)\n",
    "\n",
    "+ æ©è”½è¯­è¨€å»ºæ¨¡ï¼ˆMasked language modelingï¼ŒMLMï¼‰ï¼šæ¨¡å‹éœ€è¦æ¢å¤è¾“å…¥ä¸­è¢«\"MASK\"æ‰çš„ä¸€äº›å­—ç¬¦ï¼ˆBERTç±»æ¨¡å‹çš„é¢„è®­ç»ƒä»»åŠ¡ï¼‰ã€‚è¿™ç§æ–¹å¼æ¨¡å‹å¯ä»¥çœ‹åˆ°æ•´ä¸ªå¥å­ï¼Œå› æ­¤æ¨¡å‹å¯ä»¥æ ¹æ®â€œ\\[MASK\\]â€æ ‡è®°ä¹‹å‰å’Œä¹‹åçš„å­—ç¬¦æ¥é¢„æµ‹è¯¥ä½ç½®è¢«â€œ\\[MASK\\]â€ä¹‹å‰çš„å­—ç¬¦ã€‚\n",
    "\n",
    "![Widget inference representing the masked language modeling task](images/masked_language_modeling.png)\n",
    "\n",
    "æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†è¯´æ˜å¦‚ä½•è½»æ¾åœ°ä¸ºæ¯ä¸ªä»»åŠ¡åŠ è½½å’Œé¢„å¤„ç†æ•°æ®é›†ï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨â€œTrainerâ€APIå¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚\n",
    "\n",
    "å½“ç„¶æ‚¨ä¹Ÿå¯ä»¥ç›´æ¥åœ¨åˆ†å¸ƒå¼ç¯å¢ƒæˆ–TPUä¸Šè¿è¡Œè¯¥jupyterç¬”è®°æœ¬çš„pythonè„šæœ¬ç‰ˆæœ¬ï¼Œå¯ä»¥åœ¨[examplesæ–‡ä»¶å¤¹](https://github.com/huggingface/transformers/tree/master/examples)ä¸­æ‰¾åˆ°ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å‡†å¤‡æ•°æ®"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨æ¥ä¸‹æ¥çš„è¿™äº›ä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨[Wikitext 2](https://huggingface.co/datasets/wikitext#data-instances)æ•°æ®é›†ä½œä¸ºç¤ºä¾‹ã€‚æ‚¨å¯ä»¥é€šè¿‡ğŸ¤—Datasetsåº“åŠ è½½è¯¥æ•°æ®é›†ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "datasets = load_dataset('wikitext', 'wikitext-2-raw-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¦‚æœç¢°åˆ°ä»¥ä¸‹é”™è¯¯ï¼š\n",
    "![request Error](images/request_error.png)\n",
    "\n",
    "è§£å†³æ–¹æ¡ˆ:\n",
    "\n",
    "MACç”¨æˆ·: åœ¨ ```/etc/hosts``` æ–‡ä»¶ä¸­æ·»åŠ ä¸€è¡Œ ```199.232.68.133  raw.githubusercontent.com```\n",
    "\n",
    "Windowsoç”¨æˆ·: åœ¨ ```C:\\Windows\\System32\\drivers\\etc\\hosts```  æ–‡ä»¶ä¸­æ·»åŠ ä¸€è¡Œ ```199.232.68.133  raw.githubusercontent.com```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å½“ç„¶æ‚¨ä¹Ÿå¯ä»¥ç”¨å…¬å¼€åœ¨[hub](https://huggingface.co/datasets)ä¸Šçš„ä»»ä½•æ•°æ®é›†æ›¿æ¢ä¸Šé¢çš„æ•°æ®é›†ï¼Œæˆ–è€…ä½¿ç”¨æ‚¨è‡ªå·±çš„æ–‡ä»¶ã€‚åªéœ€å–æ¶ˆæ³¨é‡Šä»¥ä¸‹å•å…ƒæ ¼ï¼Œå¹¶å°†è·¯å¾„æ›¿æ¢ä¸ºå°†å¯¼è‡´æ‚¨çš„æ–‡ä»¶è·¯å¾„ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets = load_dataset(\"text\", data_files={\"train\": path_to_train.txt, \"validation\": path_to_validation.txt}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ‚¨è¿˜å¯ä»¥ä»csvæˆ–JSONæ–‡ä»¶åŠ è½½æ•°æ®é›†ï¼Œæ›´å¤šä¿¡æ¯è¯·å‚é˜…[å®Œæ•´æ–‡æ¡£](https://huggingface.co/docs/datasets/loading_datasets.html#from-local-files)ã€‚\n",
    "\n",
    "è¦è®¿é—®ä¸€ä¸ªæ•°æ®ä¸­å®é™…çš„å…ƒç´ ï¼Œæ‚¨éœ€è¦å…ˆé€‰æ‹©ä¸€ä¸ªkeyï¼Œç„¶åç»™å‡ºä¸€ä¸ªç´¢å¼•:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ' The game \\'s battle system , the BliTZ system , is carried over directly from Valkyira Chronicles . During missions , players select each unit using a top @-@ down perspective of the battlefield map : once a character is selected , the player moves the character around the battlefield in third @-@ person . A character can only act once per @-@ turn , but characters can be granted multiple turns at the expense of other characters \\' turns . Each character has a field and distance of movement limited by their Action Gauge . Up to nine characters can be assigned to a single mission . During gameplay , characters will call out if something happens to them , such as their health points ( HP ) getting low or being knocked out by enemy attacks . Each character has specific \" Potentials \" , skills unique to each character . They are divided into \" Personal Potential \" , which are innate skills that remain unaltered unless otherwise dictated by the story and can either help or impede a character , and \" Battle Potentials \" , which are grown throughout the game and always grant boons to a character . To learn Battle Potentials , each character has a unique \" Masters Table \" , a grid @-@ based skill table that can be used to acquire and link different skills . Characters also have Special Abilities that grant them temporary boosts on the battlefield : Kurt can activate \" Direct Command \" and move around the battlefield without depleting his Action Point gauge , the character Reila can shift into her \" Valkyria Form \" and become invincible , while Imca can target multiple enemy units with her heavy weapon . \\n'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸ºäº†å¿«é€Ÿäº†è§£æ•°æ®çš„ç»“æ„ï¼Œä¸‹é¢çš„å‡½æ•°å°†æ˜¾ç¤ºæ•°æ®é›†ä¸­éšæœºé€‰å–çš„ä¸€äº›ç¤ºä¾‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import ClassLabel\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\" Gloom in the Land of Smiles \" . Time . 27 July 1970 . Retrieved 10 April 2007 . \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tropical Storm Jose was a short @-@ lived tropical storm which made landfall in central Mexico during August 2005 . Jose was the tenth named storm of the 2005 Atlantic hurricane season and the fourth of six tropical cyclones ( three hurricanes and three tropical storms ) to make landfall in Mexico in that year . \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The poem ends with an altered version of the refrain , which serves to show that although she wishes her death she is still alive and , in the final moment , allows her to end the poem instead of allowing the poem to end her : \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>R. D. Burman composed the film 's music , and the lyrics were written by Anand Bakshi . The songs used in the film , and released on the original soundtrack are listed below . Following that is a list of unused tracks and dialogues which were released later on an updated soundtrack . The album 's cover image depicts an emotional scene from the film in which Basanti is forced to sing and dance on the song \" Haa Jab Tak Hai Jaan \" on broken glass under the blazing sun to save Veeru 's life . \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Mets promoted deGrom to the major leagues on May 12 , 2014 , after Gonzalez Germen was placed on the disabled list . The Mets planned to use deGrom in relief , but an injury to Dillon Gee required the Mets to insert him into their starting rotation . DeGrom made his major league debut on May 15 against cross @-@ town rival New York Yankees in Citi Field . He faced fellow rookie Chase Whitley , also making his MLB debut . He pitched seven innings , allowing only one run and striking out six , but the Yankees shut out the Mets and won 1 â€“ 0 . DeGrom also collected his first MLB hit in the game in his first career at bat . It was the first hit by a Mets pitcher in the 2014 season ending an 0 @-@ for @-@ 64 hitless streak , the worst collective mark by a pitching staff to begin a season in MLB history . \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ­£å¦‚æˆ‘ä»¬æ‰€çœ‹åˆ°çš„ï¼Œä¸€äº›æ–‡æœ¬æ˜¯ç»´åŸºç™¾ç§‘æ–‡ç« çš„å®Œæ•´æ®µè½ï¼Œè€Œå…¶ä»–çš„åªæ˜¯æ ‡é¢˜æˆ–ç©ºè¡Œã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å› æœè¯­è¨€æ¨¡å‹ï¼ˆCausal Language Modelingï¼ŒCLMï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¯¹äºå› æœè¯­è¨€æ¨¡å‹(CLM)ï¼Œæˆ‘ä»¬é¦–å…ˆè·å–åˆ°æ•°æ®é›†ä¸­çš„æ‰€æœ‰æ–‡æœ¬ï¼Œå¹¶åœ¨å®ƒä»¬è¢«åˆ†è¯åå°†å®ƒä»¬è¿æ¥èµ·æ¥ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†åœ¨ç‰¹å®šåºåˆ—é•¿åº¦çš„ä¾‹å­ä¸­æ‹†åˆ†å®ƒä»¬ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¨¡å‹å°†æ¥æ”¶å¦‚ä¸‹çš„è¿ç»­æ–‡æœ¬å—:\n",
    "\n",
    "```\n",
    "æ–‡æœ¬1\n",
    "```\n",
    "æˆ–\n",
    "```\n",
    "æ–‡æœ¬1ç»“å°¾ [BOS_TOKEN] æ–‡æœ¬2å¼€å¤´\n",
    "```\n",
    "\n",
    "å–å†³äºå®ƒä»¬æ˜¯å¦è·¨è¶Šæ•°æ®é›†ä¸­çš„å‡ ä¸ªåŸå§‹æ–‡æœ¬ã€‚æ ‡ç­¾å°†ä¸è¾“å…¥ç›¸åŒï¼Œä½†å‘å·¦ç§»åŠ¨ã€‚\n",
    "\n",
    "åœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨[`distilgpt2`](https://huggingface.co/distilgpt2) æ¨¡å‹ã€‚æ‚¨åŒæ ·ä¹Ÿå¯ä»¥é€‰æ‹©[è¿™é‡Œ](https://huggingface.co/models?filter=causal-lm)åˆ—å‡ºçš„ä»»ä½•ä¸€ä¸ªcheckpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"distilgpt2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸ºäº†ç”¨è®­ç»ƒæ¨¡å‹æ—¶ä½¿ç”¨çš„è¯æ±‡å¯¹æ‰€æœ‰æ–‡æœ¬è¿›è¡Œæ ‡è®°ï¼Œæˆ‘ä»¬å¿…é¡»ä¸‹è½½ä¸€ä¸ªé¢„å…ˆè®­ç»ƒè¿‡çš„åˆ†è¯å™¨ï¼ˆTokenizerï¼‰ã€‚è€Œè¿™äº›æ“ä½œéƒ½å¯ä»¥ç”±AutoTokenizerç±»å®Œæˆ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬ç°åœ¨å¯ä»¥å¯¹æ‰€æœ‰çš„æ–‡æœ¬è°ƒç”¨åˆ†è¯å™¨ï¼Œè¯¥æ“ä½œå¯ä»¥ç®€å•åœ°ä½¿ç”¨æ¥è‡ªDatasetsåº“çš„mapæ–¹æ³•å®ç°ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å®šä¹‰ä¸€ä¸ªåœ¨æ–‡æœ¬ä¸Šè°ƒç”¨æ ‡è®°å™¨çš„å‡½æ•°:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç„¶åæˆ‘ä»¬å°†å®ƒåº”ç”¨åˆ°datasetså¯¹è±¡ä¸­çš„åˆ†è¯ï¼Œä½¿ç”¨```batch=True```å’Œ```4```ä¸ªè¿›ç¨‹æ¥åŠ é€Ÿé¢„å¤„ç†ã€‚è€Œä¹‹åæˆ‘ä»¬å¹¶ä¸éœ€è¦```text```åˆ—ï¼Œæ‰€ä»¥å°†å…¶èˆå¼ƒã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-add63507b55dada6.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-2f5fe078cf165e44.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-e27aefc304fc53ec.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-6603c9dc956f243a.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-4bd115f7b67a72a9.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-35b0565918c16f06.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-50c4a5ff680186cd.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-9515c657674e62d5.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-194f1d1d280a5be2.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-689990adb8104673.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-75e90f2db8ec512a.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-2e111ac0eb460848.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = datasets.map(tokenize_function, batched=True, num_proc=4, remove_columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¦‚æœæˆ‘ä»¬ç°åœ¨æŸ¥çœ‹æ•°æ®é›†çš„ä¸€ä¸ªå…ƒç´ ï¼Œæˆ‘ä»¬ä¼šçœ‹åˆ°æ–‡æœ¬å·²ç»è¢«æ¨¡å‹æ‰€éœ€çš„input_idsæ‰€å–ä»£:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 'input_ids': [796, 569, 18354, 7496, 17740, 6711, 796, 220, 198]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸‹ä¸€æ­¥å°±æœ‰ç‚¹å°å›°éš¾äº†ï¼šæˆ‘ä»¬éœ€è¦å°†æ‰€æœ‰æ–‡æœ¬è¿æ¥åœ¨ä¸€èµ·ï¼Œç„¶åå°†ç»“æœåˆ†å‰²æˆç‰¹å®š`block_size`çš„å°å—ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†å†æ¬¡ä½¿ç”¨`map`æ–¹æ³•ï¼Œå¹¶ä½¿ç”¨é€‰é¡¹`batch=True`ã€‚è¿™ä¸ªé€‰é¡¹å…è®¸æˆ‘ä»¬é€šè¿‡è¿”å›ä¸åŒæ•°é‡çš„æ ·æœ¬æ¥æ”¹å˜æ•°æ®é›†ä¸­çš„æ ·æœ¬æ•°é‡ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæˆ‘ä»¬å¯ä»¥ä»ä¸€æ‰¹ç¤ºä¾‹ä¸­åˆ›å»ºæ–°çš„ç¤ºä¾‹ã€‚\n",
    "\n",
    "é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦è·å–é¢„è®­ç»ƒæ¨¡å‹æ—¶æ‰€ä½¿ç”¨çš„æœ€å¤§é•¿åº¦ã€‚æœ€å¤§é•¿åº¦åœ¨è¿™é‡Œè®¾ç½®ä¸º128ï¼Œä»¥é˜²æ‚¨çš„æ˜¾å­˜çˆ†ç‚¸ğŸ’¥ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# block_size = tokenizer.model_max_length\n",
    "block_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç„¶åæˆ‘ä»¬ç¼–å†™é¢„å¤„ç†å‡½æ•°æ¥å¯¹æˆ‘ä»¬çš„æ–‡æœ¬è¿›è¡Œåˆ†ç»„:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    # æ‹¼æ¥æ‰€æœ‰æ–‡æœ¬\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # æˆ‘ä»¬å°†ä½™æ•°å¯¹åº”çš„éƒ¨åˆ†å»æ‰ã€‚ä½†å¦‚æœæ¨¡å‹æ”¯æŒçš„è¯ï¼Œå¯ä»¥æ·»åŠ paddingï¼Œæ‚¨å¯ä»¥æ ¹æ®éœ€è¦å®šåˆ¶æ­¤éƒ¨ä»¶ã€‚\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # é€šè¿‡max_lenè¿›è¡Œåˆ†å‰²ã€‚\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é¦–å…ˆæ³¨æ„ï¼Œæˆ‘ä»¬å¤åˆ¶äº†æ ‡ç­¾çš„è¾“å…¥ã€‚\n",
    "\n",
    "è¿™æ˜¯å› ä¸ºğŸ¤—transformeråº“çš„æ¨¡å‹é»˜è®¤å‘å³ç§»åŠ¨ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¸éœ€è¦æ‰‹åŠ¨æ“ä½œã€‚\n",
    "\n",
    "è¿˜è¦æ³¨æ„ï¼Œåœ¨é»˜è®¤æƒ…å†µä¸‹ï¼Œ`map`æ–¹æ³•å°†å‘é€ä¸€æ‰¹1,000ä¸ªç¤ºä¾‹ï¼Œç”±é¢„å¤„ç†å‡½æ•°å¤„ç†ã€‚å› æ­¤ï¼Œåœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†åˆ é™¤å‰©ä½™éƒ¨åˆ†ï¼Œä½¿è¿æ¥çš„æ ‡è®°åŒ–æ–‡æœ¬æ¯1000ä¸ªç¤ºä¾‹ä¸º`block_size`çš„å€æ•°ã€‚æ‚¨å¯ä»¥é€šè¿‡ä¼ é€’æ›´é«˜çš„æ‰¹å¤„ç†å¤§å°æ¥è°ƒæ•´æ­¤è¡Œä¸º(å½“ç„¶è¿™ä¹Ÿä¼šè¢«å¤„ç†å¾—æ›´æ…¢)ã€‚ä½ ä¹Ÿå¯ä»¥ä½¿ç”¨`multiprocessing`æ¥åŠ é€Ÿé¢„å¤„ç†:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-7922a655a273877b.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-1574e22b98e4bda6.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-f49040f4066ebe1b.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-d73906ef1f7c1680.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-9d74e0ff16bb0685.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-1503fc13f68a3ced.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-b297a7932166f590.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-5964633ea9ee8dc3.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-c67bc90519e49edb.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-29552710c3e3ce38.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-320c4257ee2592e1.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-915f4807a6d9984e.arrow\n"
     ]
    }
   ],
   "source": [
    "lm_datasets = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨æˆ‘ä»¬å¯ä»¥æ£€æŸ¥æ•°æ®é›†æ˜¯å¦å‘ç”Ÿäº†å˜åŒ–ï¼šç°åœ¨æ ·æœ¬åŒ…å«äº†`block_size`è¿ç»­å­—ç¬¦å—ï¼Œå¯èƒ½è·¨è¶Šäº†å‡ ä¸ªåŸå§‹æ–‡æœ¬ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' game and follows the \" Nameless \", a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" Calamaty Raven \". \\n The game began development in 2010, carrying over a large portion of the work done on Valkyria Chronicles II. While it retained the standard features of the series, it also underwent multiple adjustments, such as making the game more forgiving for series newcomers. Character designer Raita Honjou and composer Hitoshi Sakimoto both returned from previous entries, along with Valkyria Chronicles II director Takeshi Oz'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(lm_datasets[\"train\"][1][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ—¢ç„¶æ•°æ®å·²ç»æ¸…ç†å®Œæ¯•ï¼Œæˆ‘ä»¬å°±å¯ä»¥å®ä¾‹åŒ–æˆ‘ä»¬çš„è®­ç»ƒå™¨äº†ã€‚æˆ‘ä»¬å°†å»ºç«‹ä¸€ä¸ªæ¨¡å‹:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ£€æŸ¥torchç‰ˆæœ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1.8.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import importlib.util\n",
    "import importlib_metadata\n",
    "a = importlib.util.find_spec(\"torch\") is not None\n",
    "print(a)\n",
    "_torch_version = importlib_metadata.version(\"torch\")\n",
    "print(_torch_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å’Œä¸€äº›`TrainingArguments`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    \"test-clm\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬æŠŠè¿™äº›éƒ½ä¼ é€’ç»™`Trainer`ç±»:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_datasets[\"train\"],\n",
    "    eval_dataset=lm_datasets[\"validation\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç„¶åå°±å¯ä»¥è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹ğŸŒ¶:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='4' max='7002' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   4/7002 00:26 < 25:42:43, 0.08 it/s, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='3' max='242' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  3/242 00:08 < 16:51, 0.24 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/transformers/src/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, **kwargs)\u001b[0m\n\u001b[1;32m   1048\u001b[0m                         \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m                     \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_flos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/transformers/src/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1450\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1452\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1454\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸€æ—¦è®­ç»ƒå®Œæˆï¼Œæˆ‘ä»¬å°±å¯ä»¥è¯„ä¼°æˆ‘ä»¬çš„æ¨¡å‹ï¼Œå¾—åˆ°å®ƒåœ¨éªŒè¯é›†ä¸Šçš„perplexityï¼Œå¦‚ä¸‹æ‰€ç¤º:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-75f05755702f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0meval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/transformers/src/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   1656\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m         output = self.prediction_loop(\n\u001b[0m\u001b[1;32m   1659\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/transformers/src/transformers/trainer.py\u001b[0m in \u001b[0;36mprediction_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   1794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1795\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1796\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1797\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1798\u001b[0m                 \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/transformers/src/transformers/trainer.py\u001b[0m in \u001b[0;36mprediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m   1908\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1909\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhas_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1910\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1911\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/transformers/src/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   1464\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1465\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1466\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1467\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1468\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/transformers/src/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    924\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m         \u001b[0mlm_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import math\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ©è”½è¯­è¨€æ¨¡å‹ï¼ˆMask Language Modelingï¼ŒMLMï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ©è”½è¯­è¨€æ¨¡å‹(MLM)æˆ‘ä»¬å°†ä½¿ç”¨ç›¸åŒçš„æ•°æ®é›†é¢„å¤„ç†å’Œä»¥å‰ä¸€æ ·ç”¨ä¸€ä¸ªé¢å¤–çš„æ­¥éª¤ï¼š\n",
    "\n",
    "æˆ‘ä»¬å°†éšæœº\"MASK\"ä¸€äº›å­—ç¬¦(ä½¿ç”¨\"[MASK]\"è¿›è¡Œæ›¿æ¢)ä»¥åŠè°ƒæ•´æ ‡ç­¾ä¸ºåªåŒ…å«åœ¨\"[MASK]\"ä½ç½®å¤„çš„æ ‡ç­¾(å› ä¸ºæˆ‘ä»¬ä¸éœ€è¦é¢„æµ‹æ²¡æœ‰è¢«\"MASK\"çš„å­—ç¬¦)ã€‚\n",
    "\n",
    "åœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨[`distilroberta-base`](https://huggingface.co/distilroberta-base)æ¨¡å‹ã€‚æ‚¨åŒæ ·ä¹Ÿå¯ä»¥é€‰æ‹©[è¿™é‡Œ](https://huggingface.co/models?filter=causal-lm)åˆ—å‡ºçš„ä»»ä½•ä¸€ä¸ªcheckpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"distilroberta-base\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬å¯ä»¥åƒä¹‹å‰ä¸€æ ·åº”ç”¨ç›¸åŒçš„åˆ†è¯å™¨å‡½æ•°ï¼Œæˆ‘ä»¬åªéœ€è¦æ›´æ–°æˆ‘ä»¬çš„åˆ†è¯å™¨æ¥ä½¿ç”¨åˆšåˆšé€‰æ‹©çš„checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd4dc3d0bdd4659a59a50fdc8541988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2460826b91a4385918e14533b07c383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19f137fe3b2b458eb9dee5ced661b225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355863.0, style=ProgressStyle(descriptâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (544 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (638 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (522 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "tokenized_datasets = datasets.map(tokenize_function, batched=True, num_proc=4, remove_columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åƒä¹‹å‰ä¸€æ ·ï¼Œæˆ‘ä»¬æŠŠæ–‡æœ¬åˆ†ç»„åœ¨ä¸€èµ·ï¼Œå¹¶æŠŠå®ƒä»¬åˆ†æˆé•¿åº¦ä¸º`block_size`çš„æ ·æœ¬ã€‚å¦‚æœæ‚¨çš„æ•°æ®é›†ç”±å•ç‹¬çš„å¥å­ç»„æˆï¼Œåˆ™å¯ä»¥è·³è¿‡è¿™ä¸€æ­¥ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-193b20de9c871606.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-97836f63a281b270.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-63049d6204a5654b.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-e9ceefd896404e5c.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-1171f2a1c38b729d.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-a892f07e4b389c49.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-8863733562dc0129.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-669b460867b7880e.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-bbbf00bf3924b6d4.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-0cf5af695a224e20.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-f31e6c33364b40dd.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-c291d0cec11060a1.arrow\n"
     ]
    }
   ],
   "source": [
    "lm_datasets = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å‰©ä¸‹çš„å’Œæˆ‘ä»¬ä¹‹å‰çš„åšæ³•éå¸¸ç›¸ä¼¼ï¼Œåªæœ‰ä¸¤ä¸ªä¾‹å¤–ã€‚é¦–å…ˆæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªé€‚åˆæ©è”½è¯­è¨€æ¨¡å‹çš„æ¨¡å‹:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å…¶æ¬¡ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªç‰¹æ®Šçš„data_collatorã€‚data_collatoræ˜¯ä¸€ä¸ªå‡½æ•°ï¼Œè´Ÿè´£è·å–æ ·æœ¬å¹¶å°†å®ƒä»¬æ‰¹å¤„ç†æˆå¼ é‡ã€‚\n",
    "\n",
    "åœ¨å‰é¢çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬æ²¡æœ‰ä»€ä¹ˆç‰¹æ®Šçš„äº‹æƒ…è¦åšï¼Œæ‰€ä»¥æˆ‘ä»¬åªä½¿ç”¨è¿™ä¸ªå‚æ•°çš„é»˜è®¤å€¼ã€‚è¿™é‡Œæˆ‘ä»¬è¦åšéšæœº\"MASK\"ã€‚\n",
    "\n",
    "æˆ‘ä»¬å¯ä»¥å°†å…¶ä½œä¸ºé¢„å¤„ç†æ­¥éª¤(`tokenizer`)è¿›è¡Œå¤„ç†ï¼Œä½†åœ¨æ¯ä¸ªé˜¶æ®µï¼Œå­—ç¬¦æ€»æ˜¯ä»¥ç›¸åŒçš„æ–¹å¼è¢«æ©ç›–ã€‚é€šè¿‡åœ¨data_collatorä¸­æ‰§è¡Œè¿™ä¸€æ­¥ï¼Œæˆ‘ä»¬å¯ä»¥ç¡®ä¿æ¯æ¬¡æ£€æŸ¥æ•°æ®æ—¶éƒ½ä»¥æ–°çš„æ–¹å¼å®Œæˆéšæœºæ©è”½ã€‚\n",
    "\n",
    "ä¸ºäº†å®ç°æ©è”½ï¼Œ`Transformers`ä¸ºæ©è”½è¯­è¨€æ¨¡å‹æä¾›äº†ä¸€ä¸ª`DataCollatorForLanguageModeling`ã€‚æˆ‘ä»¬å¯ä»¥è°ƒæ•´æ©è”½çš„æ¦‚ç‡:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç„¶åæˆ‘ä»¬è¦æŠŠæ‰€æœ‰çš„ä¸œè¥¿äº¤ç»™trainerï¼Œç„¶åå¼€å§‹è®­ç»ƒ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a5580f1a4d07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m trainer = Trainer(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlm_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0meval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlm_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"validation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Trainer' is not defined"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_datasets[\"train\"],\n",
    "    eval_dataset=lm_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åƒä»¥å‰ä¸€æ ·ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°æˆ‘ä»¬çš„æ¨¡å‹ã€‚\n",
    "\n",
    "ä¸CLMç›®æ ‡ç›¸æ¯”ï¼Œå›°æƒ‘åº¦è¦ä½å¾—å¤šï¼Œå› ä¸ºå¯¹äºMLMç›®æ ‡ï¼Œæˆ‘ä»¬åªéœ€è¦å¯¹éšè—çš„ä»¤ç‰Œ(åœ¨è¿™é‡Œå æ€»æ•°çš„15%)è¿›è¡Œé¢„æµ‹ï¼ŒåŒæ—¶å¯ä»¥è®¿é—®å…¶ä½™çš„ä»¤ç‰Œã€‚\n",
    "\n",
    "å› æ­¤ï¼Œå¯¹äºæ¨¡å‹æ¥è¯´ï¼Œè¿™æ˜¯ä¸€é¡¹æ›´å®¹æ˜“çš„ä»»åŠ¡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-702cd39d15db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ä¸è¦å¿˜è®°å°†ä½ çš„æ¨¡å‹[ä¸Šä¼ ](https://huggingface.co/transformers/model_sharing.html)åˆ°[ğŸ¤— æ¨¡å‹ä¸­å¿ƒ](https://huggingface.co/models)ã€‚\n",
    "\n",
    "ç„¶åï¼Œæ‚¨å¯ä»¥ä½¿ç”¨å®ƒç”Ÿæˆåƒè¯¥ç¬”è®°æœ¬çš„ç¬¬ä¸€å¼ å›¾ç‰‡ä¸­æ‰€ç¤ºçš„ç»“æœ!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
