{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¦‚æœæ‚¨åœ¨colabä¸Šæ‰“å¼€è¿™ä¸ªjupyterç¬”è®°æœ¬ï¼Œæ‚¨éœ€è¦å®‰è£…ğŸ¤—Trasnformerså’ŒğŸ¤—datasetsã€‚å…·ä½“å‘½ä»¤å¦‚ä¸‹ï¼ˆå–æ¶ˆæ³¨é‡Šå¹¶è¿è¡Œï¼Œå¦‚æœé€Ÿåº¦æ…¢è¯·åˆ‡æ¢å›½å†…æºï¼ŒåŠ ä¸Šç¬¬äºŒè¡Œçš„å‚æ•°ï¼‰ã€‚\n",
    "\n",
    "åœ¨è¿è¡Œå•å…ƒæ ¼ä¹‹å‰ï¼Œæ‚¨éœ€è¦ç¡®ä¿æ‚¨ä½¿ç”¨çš„pythonç¯å¢ƒå’Œè¯¥é¡¹ç›®ä¸­çš„README.mdæ–‡ä»¶ä¸­æè¿°çš„ä¸€è‡´ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install datasets transformers \n",
    "# -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¦‚æœæ‚¨æ˜¯åœ¨æœ¬åœ°æœºå™¨ä¸Šæ‰“å¼€è¿™ä¸ªjupyterç¬”è®°æœ¬ï¼Œè¯·ç¡®ä¿æ‚¨çš„ç¯å¢ƒå®‰è£…äº†ä¸Šè¿°åº“çš„æœ€æ–°ç‰ˆæœ¬ã€‚\n",
    "\n",
    "æ‚¨å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/huggingface/transformers/tree/master/examples/language-modeling)æ‰¾åˆ°è¿™ä¸ªjupyterç¬”è®°æœ¬çš„å…·ä½“çš„pythonè„šæœ¬æ–‡ä»¶ï¼Œè¿˜å¯ä»¥é€šè¿‡åˆ†å¸ƒå¼çš„æ–¹å¼ä½¿ç”¨å¤šä¸ªgpuæˆ–tpuæ¥å¾®è°ƒæ‚¨çš„æ¨¡å‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# å¾®è°ƒæ‚¨çš„è¯­è¨€æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨å½“å‰jupyterç¬”è®°æœ¬ä¸­ï¼Œæˆ‘ä»¬å°†è¯´æ˜å¦‚ä½•ä½¿ç”¨è¯­è¨€æ¨¡å‹ä»»åŠ¡å¾®è°ƒä»»æ„[ğŸ¤—Transformers](https://github.com/huggingface/transformers) æ¨¡å‹ã€‚ \n",
    "\n",
    "æœ¬æ•™ç¨‹å°†æ¶µç›–ä¸¤ç§ç±»å‹çš„è¯­è¨€å»ºæ¨¡ä»»åŠ¡:\n",
    "\n",
    "+ å› æœè¯­è¨€æ¨¡å‹ï¼ˆCausal language modelingï¼ŒCLMï¼‰ï¼šæ¨¡å‹éœ€è¦é¢„æµ‹å¥å­ä¸­çš„ä¸‹ä¸€ä½ç½®å¤„çš„å­—ç¬¦ï¼ˆç±»ä¼¼BERTç±»æ¨¡å‹çš„decoderå’ŒGPTï¼Œä»å·¦å¾€å³è¾“å…¥å­—ç¬¦ï¼‰ã€‚ä¸ºäº†ç¡®ä¿æ¨¡å‹ä¸ä½œå¼Šï¼Œæ¨¡å‹ä¼šä½¿ç”¨ä¸€ä¸ªæ³¨æ„æ©ç é˜²æ­¢æ¨¡å‹çœ‹åˆ°ä¹‹åçš„å­—ç¬¦ã€‚ä¾‹å¦‚ï¼Œå½“æ¨¡å‹è¯•å›¾é¢„æµ‹å¥å­ä¸­çš„i+1ä½ç½®å¤„çš„å­—ç¬¦æ—¶ï¼Œè¿™ä¸ªæ©ç å°†é˜»æ­¢å®ƒè®¿é—®iä½ç½®ä¹‹åçš„å­—ç¬¦ã€‚\n",
    "\n",
    "![æ¨ç†è¡¨ç¤ºå› æœè¯­è¨€å»ºæ¨¡ä»»åŠ¡å›¾ç‰‡](images/causal_language_modeling.png)\n",
    "\n",
    "+ æ©è”½è¯­è¨€å»ºæ¨¡ï¼ˆMasked language modelingï¼ŒMLMï¼‰ï¼šæ¨¡å‹éœ€è¦æ¢å¤è¾“å…¥ä¸­è¢«\"MASK\"æ‰çš„ä¸€äº›å­—ç¬¦ï¼ˆBERTç±»æ¨¡å‹çš„é¢„è®­ç»ƒä»»åŠ¡ï¼‰ã€‚è¿™ç§æ–¹å¼æ¨¡å‹å¯ä»¥çœ‹åˆ°æ•´ä¸ªå¥å­ï¼Œå› æ­¤æ¨¡å‹å¯ä»¥æ ¹æ®â€œ\\[MASK\\]â€æ ‡è®°ä¹‹å‰å’Œä¹‹åçš„å­—ç¬¦æ¥é¢„æµ‹è¯¥ä½ç½®è¢«â€œ\\[MASK\\]â€ä¹‹å‰çš„å­—ç¬¦ã€‚\n",
    "\n",
    "![Widget inference representing the masked language modeling task](images/masked_language_modeling.png)\n",
    "\n",
    "æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†è¯´æ˜å¦‚ä½•è½»æ¾åœ°ä¸ºæ¯ä¸ªä»»åŠ¡åŠ è½½å’Œé¢„å¤„ç†æ•°æ®é›†ï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨â€œTrainerâ€APIå¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚\n",
    "\n",
    "å½“ç„¶æ‚¨ä¹Ÿå¯ä»¥ç›´æ¥åœ¨åˆ†å¸ƒå¼ç¯å¢ƒæˆ–TPUä¸Šè¿è¡Œè¯¥jupyterç¬”è®°æœ¬çš„pythonè„šæœ¬ç‰ˆæœ¬ï¼Œå¯ä»¥åœ¨[examplesæ–‡ä»¶å¤¹](https://github.com/huggingface/transformers/tree/master/examples)ä¸­æ‰¾åˆ°ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å‡†å¤‡æ•°æ®"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨æ¥ä¸‹æ¥çš„è¿™äº›ä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨[Wikitext 2](https://huggingface.co/datasets/wikitext#data-instances)æ•°æ®é›†ä½œä¸ºç¤ºä¾‹ã€‚æ‚¨å¯ä»¥é€šè¿‡ğŸ¤—Datasetsåº“åŠ è½½è¯¥æ•°æ®é›†ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "datasets = load_dataset('wikitext', 'wikitext-2-raw-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¦‚æœç¢°åˆ°ä»¥ä¸‹é”™è¯¯ï¼š\n",
    "![request Error](images/request_error.png)\n",
    "\n",
    "è§£å†³æ–¹æ¡ˆ:\n",
    "\n",
    "MACç”¨æˆ·: åœ¨ ```/etc/hosts``` æ–‡ä»¶ä¸­æ·»åŠ ä¸€è¡Œ ```199.232.68.133  raw.githubusercontent.com```\n",
    "\n",
    "Windowsoç”¨æˆ·: åœ¨ ```C:\\Windows\\System32\\drivers\\etc\\hosts```  æ–‡ä»¶ä¸­æ·»åŠ ä¸€è¡Œ ```199.232.68.133  raw.githubusercontent.com```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å½“ç„¶æ‚¨ä¹Ÿå¯ä»¥ç”¨å…¬å¼€åœ¨[hub](https://huggingface.co/datasets)ä¸Šçš„ä»»ä½•æ•°æ®é›†æ›¿æ¢ä¸Šé¢çš„æ•°æ®é›†ï¼Œæˆ–è€…ä½¿ç”¨æ‚¨è‡ªå·±çš„æ–‡ä»¶ã€‚åªéœ€å–æ¶ˆæ³¨é‡Šä»¥ä¸‹å•å…ƒæ ¼ï¼Œå¹¶å°†è·¯å¾„æ›¿æ¢ä¸ºå°†å¯¼è‡´æ‚¨çš„æ–‡ä»¶è·¯å¾„ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets = load_dataset(\"text\", data_files={\"train\": path_to_train.txt, \"validation\": path_to_validation.txt}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ‚¨è¿˜å¯ä»¥ä»csvæˆ–JSONæ–‡ä»¶åŠ è½½æ•°æ®é›†ï¼Œæ›´å¤šä¿¡æ¯è¯·å‚é˜…[å®Œæ•´æ–‡æ¡£](https://huggingface.co/docs/datasets/loading_datasets.html#from-local-files)ã€‚\n",
    "\n",
    "è¦è®¿é—®ä¸€ä¸ªæ•°æ®ä¸­å®é™…çš„å…ƒç´ ï¼Œæ‚¨éœ€è¦å…ˆé€‰æ‹©ä¸€ä¸ªkeyï¼Œç„¶åç»™å‡ºä¸€ä¸ªç´¢å¼•:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ' The game \\'s battle system , the BliTZ system , is carried over directly from Valkyira Chronicles . During missions , players select each unit using a top @-@ down perspective of the battlefield map : once a character is selected , the player moves the character around the battlefield in third @-@ person . A character can only act once per @-@ turn , but characters can be granted multiple turns at the expense of other characters \\' turns . Each character has a field and distance of movement limited by their Action Gauge . Up to nine characters can be assigned to a single mission . During gameplay , characters will call out if something happens to them , such as their health points ( HP ) getting low or being knocked out by enemy attacks . Each character has specific \" Potentials \" , skills unique to each character . They are divided into \" Personal Potential \" , which are innate skills that remain unaltered unless otherwise dictated by the story and can either help or impede a character , and \" Battle Potentials \" , which are grown throughout the game and always grant boons to a character . To learn Battle Potentials , each character has a unique \" Masters Table \" , a grid @-@ based skill table that can be used to acquire and link different skills . Characters also have Special Abilities that grant them temporary boosts on the battlefield : Kurt can activate \" Direct Command \" and move around the battlefield without depleting his Action Point gauge , the character Reila can shift into her \" Valkyria Form \" and become invincible , while Imca can target multiple enemy units with her heavy weapon . \\n'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸ºäº†å¿«é€Ÿäº†è§£æ•°æ®çš„ç»“æ„ï¼Œä¸‹é¢çš„å‡½æ•°å°†æ˜¾ç¤ºæ•°æ®é›†ä¸­éšæœºé€‰å–çš„ä¸€äº›ç¤ºä¾‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import ClassLabel\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>= = = Other uses = = = \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\" Love Me Like You \" ( Exclusive Interview ) â€“ 3 : 16 \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In response , and hoping to win wider support for his government , Montfort summoned a new parliament for 20 January 1265 which continued until mid March that year . It was held at short notice , with the summons being issued on 14 December , leaving little time for attendees to respond . He summoned not only the barons , senior churchmen and two knights from each county , but also two burgesses from each of the major towns such as York , Lincoln , Sandwich , and the Cinque Ports , the first time this had been done . Due to the lack of support for Montfort among the barons , only 23 of them were summoned to parliament , in comparison to the summons issued to 120 churchmen , who largely supported the new government ; it is unknown how many burgesses were called . The event was overseen by King Henry , and held in the Palace of Westminster , London , which was the largest city in England , and whose continuing loyalty was essential to Montfort 's cause . \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\" Don 't You Wanna Stay \" is a country pop song with a length of four minutes and sixteen seconds . It incorporates melancholic guitar riff which is accompanied by classical elements such as violin . John Hill of About.com considered the song as a \" classic power ballad \" , writing \" whether you want to call the song country , pop , or something in between doesn 't matter because the chorus is so catchy that it doesn 't matter if you use an electric guitar or a steel guitar . \" It is set in common time and has a steady tempo of 72 beats per minute . It is written in the key of G @-@ sharp minor and both Aldean and Clarkson 's vocals span two octaves , from A â™¯ 3 to G â™¯ 5 . It follows the chord progression G â™¯ m â€“ E â€“ B. Bob Peacock of Roughstock thought that the structure of the song was interesting with its brief four @-@ line verses and \" don 't you wanna stay 's throughout the chorus . As the chorus of the song starts in , the sound of electric and slide guitars are prominent as Aldean and Clarkson sing , \" Don 't you wanna hold each other tight / Don 't you wanna fall asleep with me tonight ? \" \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Twenty II â€“ songwriting , vocals \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>On September 25 , 2007 , Nathan was named as one of 10 finalists for the \" DHL Delivery Man of the Year Award \" , the third year in a row that he has been a finalist . On October 29 , the Twins exercised Nathan 's club option for 2008 . \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ­£å¦‚æˆ‘ä»¬æ‰€çœ‹åˆ°çš„ï¼Œä¸€äº›æ–‡æœ¬æ˜¯ç»´åŸºç™¾ç§‘æ–‡ç« çš„å®Œæ•´æ®µè½ï¼Œè€Œå…¶ä»–çš„åªæ˜¯æ ‡é¢˜æˆ–ç©ºè¡Œã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å› æœè¯­è¨€æ¨¡å‹ï¼ˆCausal Language Modelingï¼ŒCLMï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¯¹äºå› æœè¯­è¨€æ¨¡å‹(CLM)ï¼Œæˆ‘ä»¬é¦–å…ˆè·å–åˆ°æ•°æ®é›†ä¸­çš„æ‰€æœ‰æ–‡æœ¬ï¼Œå¹¶åœ¨å®ƒä»¬è¢«åˆ†è¯åå°†å®ƒä»¬è¿æ¥èµ·æ¥ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†åœ¨ç‰¹å®šåºåˆ—é•¿åº¦çš„ä¾‹å­ä¸­æ‹†åˆ†å®ƒä»¬ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¨¡å‹å°†æ¥æ”¶å¦‚ä¸‹çš„è¿ç»­æ–‡æœ¬å—:\n",
    "\n",
    "```\n",
    "æ–‡æœ¬1\n",
    "```\n",
    "æˆ–\n",
    "```\n",
    "æ–‡æœ¬1ç»“å°¾ [BOS_TOKEN] æ–‡æœ¬2å¼€å¤´\n",
    "```\n",
    "\n",
    "å–å†³äºå®ƒä»¬æ˜¯å¦è·¨è¶Šæ•°æ®é›†ä¸­çš„å‡ ä¸ªåŸå§‹æ–‡æœ¬ã€‚æ ‡ç­¾å°†ä¸è¾“å…¥ç›¸åŒï¼Œä½†å‘å·¦ç§»åŠ¨ã€‚\n",
    "\n",
    "åœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨[`distilgpt2`](https://huggingface.co/distilgpt2) æ¨¡å‹ã€‚æ‚¨åŒæ ·ä¹Ÿå¯ä»¥é€‰æ‹©[è¿™é‡Œ](https://huggingface.co/models?filter=causal-lm)åˆ—å‡ºçš„ä»»ä½•ä¸€ä¸ªcheckpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"distilgpt2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸ºäº†ç”¨è®­ç»ƒæ¨¡å‹æ—¶ä½¿ç”¨çš„è¯æ±‡å¯¹æ‰€æœ‰æ–‡æœ¬è¿›è¡Œæ ‡è®°ï¼Œæˆ‘ä»¬å¿…é¡»ä¸‹è½½ä¸€ä¸ªé¢„å…ˆè®­ç»ƒè¿‡çš„åˆ†è¯å™¨ï¼ˆTokenizerï¼‰ã€‚è€Œè¿™äº›æ“ä½œéƒ½å¯ä»¥ç”±AutoTokenizerç±»å®Œæˆ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬ç°åœ¨å¯ä»¥å¯¹æ‰€æœ‰çš„æ–‡æœ¬è°ƒç”¨åˆ†è¯å™¨ï¼Œè¯¥æ“ä½œå¯ä»¥ç®€å•åœ°ä½¿ç”¨æ¥è‡ªDatasetsåº“çš„mapæ–¹æ³•å®ç°ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å®šä¹‰ä¸€ä¸ªåœ¨æ–‡æœ¬ä¸Šè°ƒç”¨æ ‡è®°å™¨çš„å‡½æ•°:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç„¶åæˆ‘ä»¬å°†å®ƒåº”ç”¨åˆ°datasetså¯¹è±¡ä¸­çš„åˆ†è¯ï¼Œä½¿ç”¨```batch=True```å’Œ```4```ä¸ªè¿›ç¨‹æ¥åŠ é€Ÿé¢„å¤„ç†ã€‚è€Œä¹‹åæˆ‘ä»¬å¹¶ä¸éœ€è¦```text```åˆ—ï¼Œæ‰€ä»¥å°†å…¶èˆå¼ƒã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-add63507b55dada6.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-e27aefc304fc53ec.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-2f5fe078cf165e44.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-6603c9dc956f243a.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-35b0565918c16f06.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-4bd115f7b67a72a9.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-50c4a5ff680186cd.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-9515c657674e62d5.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-75e90f2db8ec512a.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-689990adb8104673.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-194f1d1d280a5be2.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-2e111ac0eb460848.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = datasets.map(tokenize_function, batched=True, num_proc=4, remove_columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¦‚æœæˆ‘ä»¬ç°åœ¨æŸ¥çœ‹æ•°æ®é›†çš„ä¸€ä¸ªå…ƒç´ ï¼Œæˆ‘ä»¬ä¼šçœ‹åˆ°æ–‡æœ¬å·²ç»è¢«æ¨¡å‹æ‰€éœ€çš„input_idsæ‰€å–ä»£:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 'input_ids': [796, 569, 18354, 7496, 17740, 6711, 796, 220, 198]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸‹ä¸€æ­¥å°±æœ‰ç‚¹å°å›°éš¾äº†ï¼šæˆ‘ä»¬éœ€è¦å°†æ‰€æœ‰æ–‡æœ¬è¿æ¥åœ¨ä¸€èµ·ï¼Œç„¶åå°†ç»“æœåˆ†å‰²æˆç‰¹å®š`block_size`çš„å°å—ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†å†æ¬¡ä½¿ç”¨`map`æ–¹æ³•ï¼Œå¹¶ä½¿ç”¨é€‰é¡¹`batch=True`ã€‚è¿™ä¸ªé€‰é¡¹å…è®¸æˆ‘ä»¬é€šè¿‡è¿”å›ä¸åŒæ•°é‡çš„æ ·æœ¬æ¥æ”¹å˜æ•°æ®é›†ä¸­çš„æ ·æœ¬æ•°é‡ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæˆ‘ä»¬å¯ä»¥ä»ä¸€æ‰¹ç¤ºä¾‹ä¸­åˆ›å»ºæ–°çš„ç¤ºä¾‹ã€‚\n",
    "\n",
    "é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦è·å–é¢„è®­ç»ƒæ¨¡å‹æ—¶æ‰€ä½¿ç”¨çš„æœ€å¤§é•¿åº¦ã€‚æœ€å¤§é•¿åº¦åœ¨è¿™é‡Œè®¾ç½®ä¸º128ï¼Œä»¥é˜²æ‚¨çš„æ˜¾å­˜çˆ†ç‚¸ğŸ’¥ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# block_size = tokenizer.model_max_length\n",
    "block_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç„¶åæˆ‘ä»¬ç¼–å†™é¢„å¤„ç†å‡½æ•°æ¥å¯¹æˆ‘ä»¬çš„æ–‡æœ¬è¿›è¡Œåˆ†ç»„:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    # æ‹¼æ¥æ‰€æœ‰æ–‡æœ¬\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # æˆ‘ä»¬å°†ä½™æ•°å¯¹åº”çš„éƒ¨åˆ†å»æ‰ã€‚ä½†å¦‚æœæ¨¡å‹æ”¯æŒçš„è¯ï¼Œå¯ä»¥æ·»åŠ paddingï¼Œæ‚¨å¯ä»¥æ ¹æ®éœ€è¦å®šåˆ¶æ­¤éƒ¨ä»¶ã€‚\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # é€šè¿‡max_lenè¿›è¡Œåˆ†å‰²ã€‚\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é¦–å…ˆæ³¨æ„ï¼Œæˆ‘ä»¬å¤åˆ¶äº†æ ‡ç­¾çš„è¾“å…¥ã€‚\n",
    "\n",
    "è¿™æ˜¯å› ä¸ºğŸ¤—transformeråº“çš„æ¨¡å‹é»˜è®¤å‘å³ç§»åŠ¨ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¸éœ€è¦æ‰‹åŠ¨æ“ä½œã€‚\n",
    "\n",
    "è¿˜è¦æ³¨æ„ï¼Œåœ¨é»˜è®¤æƒ…å†µä¸‹ï¼Œ`map`æ–¹æ³•å°†å‘é€ä¸€æ‰¹1,000ä¸ªç¤ºä¾‹ï¼Œç”±é¢„å¤„ç†å‡½æ•°å¤„ç†ã€‚å› æ­¤ï¼Œåœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†åˆ é™¤å‰©ä½™éƒ¨åˆ†ï¼Œä½¿è¿æ¥çš„æ ‡è®°åŒ–æ–‡æœ¬æ¯1000ä¸ªç¤ºä¾‹ä¸º`block_size`çš„å€æ•°ã€‚æ‚¨å¯ä»¥é€šè¿‡ä¼ é€’æ›´é«˜çš„æ‰¹å¤„ç†å¤§å°æ¥è°ƒæ•´æ­¤è¡Œä¸º(å½“ç„¶è¿™ä¹Ÿä¼šè¢«å¤„ç†å¾—æ›´æ…¢)ã€‚ä½ ä¹Ÿå¯ä»¥ä½¿ç”¨`multiprocessing`æ¥åŠ é€Ÿé¢„å¤„ç†:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-7922a655a273877b.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-1574e22b98e4bda6.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-f49040f4066ebe1b.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-d73906ef1f7c1680.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-9d74e0ff16bb0685.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-1503fc13f68a3ced.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-b297a7932166f590.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-5964633ea9ee8dc3.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-c67bc90519e49edb.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-29552710c3e3ce38.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-320c4257ee2592e1.arrow\n",
      "Loading cached processed dataset at /Users/caijie/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-915f4807a6d9984e.arrow\n"
     ]
    }
   ],
   "source": [
    "lm_datasets = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨æˆ‘ä»¬å¯ä»¥æ£€æŸ¥æ•°æ®é›†æ˜¯å¦å‘ç”Ÿäº†å˜åŒ–ï¼šç°åœ¨æ ·æœ¬åŒ…å«äº†`block_size`è¿ç»­å­—ç¬¦å—ï¼Œå¯èƒ½è·¨è¶Šäº†å‡ ä¸ªåŸå§‹æ–‡æœ¬ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' game and follows the \" Nameless \", a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" Calamaty Raven \". \\n The game began development in 2010, carrying over a large portion of the work done on Valkyria Chronicles II. While it retained the standard features of the series, it also underwent multiple adjustments, such as making the game more forgiving for series newcomers. Character designer Raita Honjou and composer Hitoshi Sakimoto both returned from previous entries, along with Valkyria Chronicles II director Takeshi Oz'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(lm_datasets[\"train\"][1][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ—¢ç„¶æ•°æ®å·²ç»æ¸…ç†å®Œæ¯•ï¼Œæˆ‘ä»¬å°±å¯ä»¥å®ä¾‹åŒ–æˆ‘ä»¬çš„è®­ç»ƒå™¨äº†ã€‚æˆ‘ä»¬å°†å»ºç«‹ä¸€ä¸ªæ¨¡å‹:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nAutoModelForCausalLM requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-294c052ce7b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/transformers/src/transformers/utils/dummy_pt_objects.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0mrequires_pytorch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/transformers/src/transformers/file_utils.py\u001b[0m in \u001b[0;36mrequires_pytorch\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__name__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPYTORCH_IMPORT_ERROR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: \nAutoModelForCausalLM requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1.8.1\n"
     ]
    }
   ],
   "source": [
    "import importlib.util\n",
    "import importlib_metadata\n",
    "a = importlib.util.find_spec(\"torch\") is not None\n",
    "print(a)\n",
    "_torch_version = importlib_metadata.version(\"torch\")\n",
    "print(_torch_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å’Œä¸€äº›`TrainingArguments`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    \"test-clm\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬æŠŠè¿™äº›éƒ½ä¼ é€’ç»™`Trainer`ç±»:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-1a5846780f93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer = Trainer(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlm_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0meval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlm_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"validation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_datasets[\"train\"],\n",
    "    eval_dataset=lm_datasets[\"validation\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
